version: '2'

services:
  ###
  # Spark sensor demo pipeline
  ###
  hdfs:
    image: sequenceiq/hadoop-docker:2.6.0
    volumes:
      - ./data/hdfs:/data
    environment:
      INIT_DAEMON_STEP: setup_hdfs
  master:
    image: bde2020/spark-master:1.5.1-hadoop2.6
    hostname: spark-master
    environment:
      INIT_DAEMON_STEP: setup_spark
    volumes:
      - ./data/spark-master:/data
  worker:
    image: bde2020/spark-worker:1.5.1-hadoop2.6
    links:
      - "master:spark-master"
  demo:
    image: bde2020/demo-spark-sensor-data:v1.2.0
    environment:
      INIT_DAEMON_STEP: compute_aggregations
    links:
      - "master:spark-master"
  ###
  # mu.semte.ch stack
  ###
  app:
    image: bde2020/pipeline-monitor-frontend:0.1.0
    links:
      - identifier:backend
    ports:
      - 80:80
  identifier:
    image: semtech/mu-identifier:1.0.0
  dispatcher:
    image: semtech/mu-dispatcher:1.0.1
    volumes:
      - ./config:/config
  database:
    image: tenforce/virtuoso:1.0.0-virtuoso7.2.2
    environment:
      SPARQL_UPDATE: "true"
      DEFAULT_GRAPH: http://mu.semte.ch/application
    ports:
      - "8890:8890"
    volumes:
      - ./data/db:/data
  pipeline:
    image: bde2020/pipeline-service:0.1.0
  initdaemon:
    image: bde2020/init-daemon-service:0.1.0

networks:
  default:
    driver: overlay

