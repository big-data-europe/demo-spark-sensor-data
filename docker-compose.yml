version: '2'

services:
  ###
  # Spark sensor demo pipeline
  ###
  namenode:
    image: bde2020/hadoop-namenode:1.0.0
    hostname: namenode
    volumes:
      - ./data/hadoop/namenode:/hadoop/dfs/name
    expose:
      - "50070"
    environment:
      CLUSTER_NAME: test
      INIT_DAEMON_STEP: setup_hdfs
      VIRTUAL_HOST: hdfs-namenode.demo.big-data-europe.local
    env_file:
      - ./config/hadoop/hadoop.env
  resourcemanager:
    image: bde2020/hadoop-resourcemanager:1.0.0
    hostname: resourcemanager
    expose:
      - "8031"
      - "8088"
    environment:
      VIRTUAL_HOST: hdfs-resourcemanager.demo.big-data-europe.local
      VIRTUAL_PORT: 8088
    env_file:
      - ./config/hadoop/hadoop.env
  historyserver:
    image: bde2020/hadoop-historyserver:1.0.0
    hostname: historyserver
    volumes:
      - ./data/hadoop/historyserver:/hadoop/yarn/timeline
    env_file:
      - ./config/hadoop/hadoop.env
  nodemanager:
    image: bde2020/hadoop-nodemanager:1.0.0
    hostname: nodemanager
    expose:
      - "8042"
    environment:
      VIRTUAL_HOST: hdfs-nodemanager.demo.big-data-europe.local
    env_file:
      - ./config/hadoop/hadoop.env
  datanode:
    image: bde2020/hadoop-datanode:1.0.0
    hostname: datanode
    env_file:
      - ./config/hadoop/hadoop.env
  filebrowser:
    image: bde2020/hdfs-filebrowser
    hostname: filebrowser
    environment:
      NAMENODE_HOST: namenode
      VIRTUAL_HOST: hue.demo.big-data-europe.local
      VIRTUAL_PORT: 8088
  master:
    image: bde2020/spark-master:1.5.1-hadoop2.6
    hostname: spark-master
    environment:
      INIT_DAEMON_STEP: setup_spark
      VIRTUAL_HOST: spark-master.demo.big-data-europe.local
      VIRTUAL_PORT: 8080
    volumes:
      - ./data/spark-master:/data
  worker:
    image: bde2020/spark-worker:1.5.1-hadoop2.6
    links:
      - "master:spark-master"
    environment:
      VIRTUAL_HOST: spark-worker.demo.big-data-europe.local
      VIRTUAL_PORT: 8081
  demo:
    image: bde2020/demo-spark-sensor-data:2.0.0
    environment:
      INIT_DAEMON_STEP: compute_aggregations
      HDFS_URL: hdfs://namenode:8020
    links:
      - "master:spark-master"
  integratorui:
    image: bde2020/integrator-ui:latest
    volumes:
      - ./config/integrator:/app/config
    environment:
      VIRTUAL_HOST: demo.big-data-europe.local
  csswrapper:
    image: madnificent/demo-spark-sensor-data-integrator-css-wrapper
    ports:
      - 80:80
    links:
      - namenode:namenode
      - resourcemanager:resourcemanager
      - nodemanager:nodemanager
      - filebrowser:filebrowser
      - master:master
      - worker:worker
      - integratorui:integratorui
      - monitor:monitor
      - database:database
    depends_on:
      - namenode
      - resourcemanager
      - nodemanager
      - filebrowser
      - master
      - worker
      - integratorui
      - monitor
      - database
  ###
  # mu.semte.ch stack
  ###
  monitor:
    image: bde2020/pipeline-monitor-frontend:0.1.0
    links:
      - identifier:backend
    environment:
      VIRTUAL_HOST: monitor.demo.big-data-europe.local
  identifier:
    image: semtech/mu-identifier:1.0.0
  dispatcher:
    image: semtech/mu-dispatcher:1.0.1
    volumes:
      - ./config:/config
  database:
    image: tenforce/virtuoso:1.0.0-virtuoso7.2.2
    environment:
      SPARQL_UPDATE: "true"
      DEFAULT_GRAPH: http://mu.semte.ch/application
      VIRTUAL_HOST: virtuoso.demo.big-data-europe.local
      VIRTUAL_PORT: 8890
    volumes:
      - ./data/db:/data
  pipeline:
    image: bde2020/mu-pipeline-service:0.1.0
  initdaemon:
    image: bde2020/mu-init-daemon-service:0.1.0
# networks:
#   default:
#     driver: overlay

